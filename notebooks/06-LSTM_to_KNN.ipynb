{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the Siamese LSTM weights for transforming the solution to KNN (cosine similarity) problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from complementary_products_suggestions import helper_functions, embeddings, config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import scikitplot as skplt\n",
    "from sklearn.metrics import classification_report\n",
    "import os\n",
    "import datetime\n",
    "import timeit\n",
    "import tensorflow.python as tf\n",
    "from tensorflow.keras.layers import Input, LSTM, dot, Embedding, Conv1D, Flatten, Dense, Dropout, Activation, MaxPooling1D, ZeroPadding1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.regularizers import l1, l2\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retreiving the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_pickle(\"../dummy_sample_matches.pickle\")\n",
    "content = pd.read_pickle(\"../dummy_sample_content.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting the data in train-test split\n",
    "We are using GroupShuffleSplit as we want to make sure that the products that appear as add-ons in the train set will not appear as an add-on in the test set. We do this to make sure that the model performance will be evaluated on unseen data (real-life scenarios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = helper_functions.train_test_split(database, 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Word2vec to create embeddings for each word in product titles based on the whole corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_weights = embeddings.word2vec(content, X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, train_set_main, train_set_addon, test_set_main, test_set_addon = helper_functions.tokenize_train_test_set(X_train, X_test, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_1 = Input(shape=(train_set_main.shape[1],))\n",
    "input_2 = Input(shape=(train_set_addon.shape[1],))\n",
    "\n",
    "common_embed = Embedding(input_dim =len(t.word_index)+1,\n",
    "                         weights=[embedding_weights],\n",
    "                         trainable=False,\n",
    "                         output_dim=config.feature_dim,\n",
    "                         input_length=30) \n",
    "\n",
    "lstm_1 = common_embed(input_1)\n",
    "lstm_2 = common_embed(input_2)\n",
    "\n",
    "common_lstm = LSTM(config.nb_neurons_lstm,\n",
    "                   return_sequences=True, \n",
    "                   activation=config.activation,\n",
    "                   kernel_regularizer=l2(config.regularizer),\n",
    "                   bias_regularizer=l2(config.regularizer),\n",
    "                   activity_regularizer=l2(config.regularizer))\n",
    "\n",
    "vector_1 = common_lstm(lstm_1)\n",
    "vector_1 = Flatten(name='flatten1')(vector_1)\n",
    "\n",
    "vector_2 = common_lstm(lstm_2)\n",
    "vector_2 = Flatten(name='flatten2')(vector_2)\n",
    "\n",
    "conc = dot([vector_1, vector_2],\n",
    "           axes=1,\n",
    "           normalize=True,\n",
    "           name='dot')\n",
    "\n",
    "x = Dense(config.nb_neurons_dense,\n",
    "          activation=config.activation,\n",
    "          name='conc_layer')(conc)\n",
    "\n",
    "x = Dropout(config.dropout_rate)(x)\n",
    "\n",
    "out = Dense(1,\n",
    "            activation=\"sigmoid\",\n",
    "            name = 'out')(x)\n",
    "\n",
    "siamese_lstm = Model([input_1, input_2],\n",
    "                     out)\n",
    "\n",
    "siamese_lstm.compile(loss='binary_crossentropy',\n",
    "                     optimizer=config.optimizer,\n",
    "                     metrics=['accuracy'])\n",
    "\n",
    "logdir = os.path.join(\"logs-lstm\",\n",
    "                      datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard = TensorBoard(logdir, histogram_freq=1)\n",
    "callbacks = [EarlyStopping(monitor='val_loss',patience=config.stop_epochs, verbose=1, mode='auto'),\n",
    "             tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Siamese LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_lstm = siamese_lstm.fit([train_set_main, train_set_addon],\n",
    "                                y_train,\n",
    "                                validation_split=0.1,\n",
    "                                batch_size=config.batch_size,\n",
    "                                epochs=config.nb_epochs,\n",
    "                                callbacks=callbacks,\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Siamese LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measuring the time needed for predicting\n",
    "start = timeit.default_timer()\n",
    "y_pred_lstm = siamese_lstm.predict([test_set_main, test_set_addon],\n",
    "                                   verbose=1)\n",
    "stop = timeit.default_timer()\n",
    "print(f\"Time: {stop-start}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining the predictons scores for the test set with the real values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_lstm = X_test\n",
    "X_test_lstm['predicted_label'] = pd.Series(np.round(y_pred_lstm.ravel(),3), index=X_test_lstm.index)\n",
    "X_test_lstm['real_label'] = pd.Series(y_test, index=X_test_lstm.index)\n",
    "X_test_lstm.tail(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for siamese lstm without word2vec\n",
    "auc = sklearn.metrics.roc_auc_score(y_test, y_pred_lstm)*100\n",
    "acc = sklearn.metrics.accuracy_score(y_test, y_pred_lstm.ravel() > 0.5)*100\n",
    "print('AUCc %s\\n' % auc)\n",
    "print('Accuracy %s\\n' % acc)\n",
    "print(sklearn.metrics.confusion_matrix(y_test, y_pred_lstm.ravel() > 0.5))\n",
    "print(classification_report(y_test, y_pred_lstm.ravel() > 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the weights from the NN before the dot product happens (basically saving the product embeddings/representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforming the test set into two lists of target and candindate products\n",
    "We only store unique products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_products_dict = pd.Series(X_test.title_main.values,index=X_test.id_main).to_dict()\n",
    "print(len(target_products_dict))\n",
    "target_products_dict.update(pd.Series(X_test.title_addon.values,index=X_test.id_addon).to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we don't know which are target which candidate so we put all products from the test set in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_products_dict = target_products_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing the target and candidate products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = X_train['title_main'].tolist() + X_train['title_addon'].tolist()\n",
    "\n",
    "t = Tokenizer(lower=True, split=' ', filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "t.fit_on_texts(seq)\n",
    "\n",
    "test_set_main = t.texts_to_sequences(list(target_products_dict.values()))\n",
    "target_products = pad_sequences(test_set_main, maxlen=30, padding='post')\n",
    "\n",
    "test_set_addon = t.texts_to_sequences(list(candidate_products_dict.values()))\n",
    "candidate_products = pad_sequences(test_set_addon, maxlen=30, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the weights for the target and candidate products "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Model(inputs=siamese_lstm.input, outputs=siamese_lstm.get_layer('flatten1').output)\n",
    "target_product_weights = m2.predict(target_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = Model(inputs=siamese_lstm.input, outputs=siamese_lstm.get_layer('flatten1').output)\n",
    "candidate_product_weights = m2.predict(candidate_products)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the cosine similarity between the two vector of target and candidate products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product = sklearn.metrics.pairwise.cosine_similarity(target_product_weights, Y=target_product_weights, dense_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_df = pd.DataFrame(dot_product, \n",
    "                             index = target_products_dict.keys(),\n",
    "                             columns = target_products_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some analysis for specific products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the top K closest products to the selected one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_product_df.nlargest(5, columns='2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a heatmap of the cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.heatmap(dot_product_df.iloc[0:2,0:2], cmap='RdYlGn', linewidths=1, annot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
